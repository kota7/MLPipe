% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mlp.R
\name{mlp}
\alias{mlp}
\alias{mlp_classifier}
\alias{mlp_regressor}
\title{Multilayer perceptron with a single hidden layer}
\usage{
mlp(...)

mlp_classifier(...)

mlp_regressor(...)
}
\arguments{
\item{...}{Parameters passed to \code{nnet::nnet}}
}
\description{
Multilayer perceptron with a single hidden layer
}
\details{
\code{mlp_classifier} is a wrapper of \code{mlp}, which sets up
appropriate parameters for classification models.

\code{mlp_regressor} is a wrapper of \code{mlp}, which sets up
appropriate parameters for regression (i.e. numeric outcome) models.
}
\examples{
# replication of \\code{\\link{nnet::nnet}} example
X <- iris[,-5]
y <- iris[,5]
samp <- c(sample(1:50,25),
          sample(51:100,25),
          sample(101:150,25))
m <- mlp(size=2, rang=0.1, decay=5e-4, maxit=200)
m$fit(list(x=X[samp,], y=nnet::class.ind(y[samp])))
table(y[-samp], max.col(m$predict(list(x=X[-samp,]))))

# Classification
m <- mlp_classifier(size=3, maxit=200)
m$fit(list(x=X[samp,], y=nnet::class.ind(y[samp])))
table(y[-samp], m$predict(list(x=X[-samp,])))

# Regression
library(mlbench)
data(BostonHousing)
X <- BostonHousing[, names(BostonHousing) != c('medv')]
y <- BostonHousing[, 'medv']
samp <- sample.int(length(y), ceiling(length(y)*0.8))
m <- mlp_regressor(size=5, maxit=200, skip=TRUE)
m$fit(list(x=X[samp,], y=y[samp]))
tbl <- cbind(y[-samp], m$predict(list(x=X[-samp,])))
cor(tbl)[2,1]
\dontrun{
plot(tbl, xlab='actual', ylab='predicted')}
}

